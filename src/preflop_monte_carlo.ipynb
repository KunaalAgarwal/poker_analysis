{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import range_construction\n",
    "import flop_classifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import random\n",
    "\n",
    "from treys import Evaluator, Card, Deck\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nUse monte-carlo simulation to determine an approximate ordering of all hands via preflop equity. \\nLaw of large numbers: as the number of random samples increases, the average of the samples will approach the true average. Caveat is the growth is asymptotic. \\nMeaning that nearing some threshold of hands, the average of the random samples is arguably good enough as an approximation of the true average. There exists a point of diminishing returns,\\nconsider computational cost and accuracy. \\n\\nAlgorithm will be: \\nFor each pair of possible starting hands, use Monte-carlo simulations to randomly determine n number of boards. At each street on the board compute the hand that is ahead via treys.evaluator.\\nThis computation will be hand_rank(hand1) - hand_rank(hand2). Add this output to some dataframe for later storage. On the flop classify the flop (determination of these classes below). \\nAt the end of the simulation, calculate the equity(hand1, hand2) via hand1_wins + hand1_ties / total_boards.  Equity(hand2, hand1) = 1 - equity(hand1, hand2).   \\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Use monte-carlo simulation to determine an approximate ordering of all hands via preflop equity. \n",
    "Law of large numbers: as the number of random samples increases, the average of the samples will approach the true average. Caveat is the growth is asymptotic. \n",
    "Meaning that nearing some threshold of hands, the average of the random samples is arguably good enough as an approximation of the true average. There exists a point of diminishing returns,\n",
    "consider computational cost and accuracy. \n",
    "\n",
    "Algorithm will be: \n",
    "For each pair of possible starting hands, use Monte-carlo simulations to randomly determine n number of boards. At each street on the board compute the hand that is ahead via treys.evaluator.\n",
    "This computation will be hand_rank(hand1) - hand_rank(hand2). Add this output to some dataframe for later storage. On the flop classify the flop (determination of these classes below). \n",
    "At the end of the simulation, calculate the equity(hand1, hand2) via hand1_wins + hand1_ties / total_boards.  Equity(hand2, hand1) = 1 - equity(hand1, hand2).   \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_placeholder_suits(hand): \n",
    "    suits = ['s', 'h', 'd', 'c']\n",
    "\n",
    "    suit1 = suits[random.randint(0,3)]\n",
    "\n",
    "    if 's' in hand: return [f\"{hand[0]}{suit1}\", f\"{hand[1]}{suit1}\"]\n",
    "\n",
    "    else:\n",
    "        suits.remove(suit1)        \n",
    "        suit2 = suits[random.randint(0,2)]\n",
    "        return [f\"{hand[0]}{suit1}\", f\"{hand[1]}{suit2}\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_unique_suits(hand1, hand2):\n",
    "    suits = ['s', 'h', 'd', 'c']\n",
    "    used_cards = set(hand1) \n",
    "    \n",
    "    for i, card2 in enumerate(hand2):\n",
    "        if card2 in used_cards:\n",
    "            rank = card2[0]  \n",
    "            # Find an available suit for this rank\n",
    "            available_suits = [suit for suit in suits if f\"{rank}{suit}\" not in used_cards]\n",
    "            if available_suits:\n",
    "                new_card = f\"{rank}{available_suits[0]}\"\n",
    "                hand2[i] = new_card\n",
    "                used_cards.add(new_card)\n",
    "        else:\n",
    "            used_cards.add(card2)  # Add non-duplicate card to the used set\n",
    "    \n",
    "    return hand1, hand2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "deck = [\n",
    "    \"2c\", \"2d\", \"2h\", \"2s\", \"3c\", \"3d\", \"3h\", \"3s\", \"4c\", \"4d\", \"4h\", \"4s\", \n",
    "    \"5c\", \"5d\", \"5h\", \"5s\", \"6c\", \"6d\", \"6h\", \"6s\", \"7c\", \"7d\", \"7h\", \"7s\", \n",
    "    \"8c\", \"8d\", \"8h\", \"8s\", \"9c\", \"9d\", \"9h\", \"9s\", \"Tc\", \"Td\", \"Th\", \"Ts\", \n",
    "    \"Jc\", \"Jd\", \"Jh\", \"Js\", \"Qc\", \"Qd\", \"Qh\", \"Qs\", \"Kc\", \"Kd\", \"Kh\", \"Ks\", \n",
    "    \"Ac\", \"Ad\", \"Ah\", \"As\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_matchup(combo, trials=10000):\n",
    "    \"\"\"\n",
    "    combo: A tuple of two hands, e.g. ('AKs', 'QQ').\n",
    "    trials: How many random flop/turn/river deals to simulate.\n",
    "    \n",
    "    Returns: A dict with:\n",
    "      {\n",
    "        'hand1': str, 'hand2': str,\n",
    "        'equity_hand1': float, 'equity_hand2': float,\n",
    "        'res': list of dicts for each Monte Carlo iteration (optional)\n",
    "      }\n",
    "    \"\"\"\n",
    "    evaluator = Evaluator()\n",
    "    \n",
    "    hand1 = assign_placeholder_suits(combo[0])\n",
    "    hand2 = assign_placeholder_suits(combo[1])\n",
    "    hand1, hand2 = ensure_unique_suits(hand1, hand2)\n",
    "    \n",
    "    hand1_cards = [Card.new(c) for c in hand1]\n",
    "    hand2_cards = [Card.new(c) for c in hand2]\n",
    "    \n",
    "    # Remove these 4 cards from the deck to create the 'remaining deck'\n",
    "    used_cards = set(hand1 + hand2)\n",
    "    remaining_deck = [card for card in deck if card not in used_cards]\n",
    "    \n",
    "    hand1_wins = 0\n",
    "    hand2_wins = 0\n",
    "    ties = 0\n",
    "    \n",
    "    # Optionally store each trial's data\n",
    "    res_local = []\n",
    "    \n",
    "    for _ in range(trials):\n",
    "        # Randomly select 5 cards for board\n",
    "        board_sample = random.sample(remaining_deck, 5)\n",
    "        board_cards = [Card.new(c) for c in board_sample]\n",
    "        \n",
    "        # Evaluate\n",
    "        hand1_rank = evaluator.evaluate(board_cards, hand1_cards)\n",
    "        hand2_rank = evaluator.evaluate(board_cards, hand2_cards)\n",
    "        \n",
    "        if hand1_rank < hand2_rank:\n",
    "            hand1_wins += 1\n",
    "        elif hand1_rank > hand2_rank:\n",
    "            hand2_wins += 1\n",
    "        else:\n",
    "            ties += 1\n",
    "        \n",
    "        # (Optional) classify flop for record-keeping\n",
    "        flop = board_sample[:3]\n",
    "        flop_qualities = [\n",
    "            flop_classifier.analyze_board_connectivity(flop),\n",
    "            flop_classifier.analyze_board_suits(flop),\n",
    "            flop_classifier.analyze_board_pairing(flop)\n",
    "        ]\n",
    "        if any(card.startswith('A') for card in flop):\n",
    "            flop_qualities.append('Ace high')\n",
    "        elif any(card.startswith('K') for card in flop):\n",
    "            flop_qualities.append('King high')\n",
    "        \n",
    "        dynamic_score = flop_classifier.determine_dynamic_score(flop)\n",
    "        \n",
    "        # res_local.append({\n",
    "        #     'hand1': hand1,\n",
    "        #     'hand2': hand2,\n",
    "        #     'flop': flop,\n",
    "        #     'turn': board_sample[3],\n",
    "        #     'river': board_sample[4],\n",
    "        #     'flop_quality': flop_qualities,\n",
    "        #     'flop_dynamic_score': dynamic_score\n",
    "        # })\n",
    "    \n",
    "    total_simulations = hand1_wins + hand2_wins + ties\n",
    "    equity_hand1 = (hand1_wins + ties / 2.0) / total_simulations\n",
    "    equity_hand2 = 1.0 - equity_hand1\n",
    "    \n",
    "    return {\n",
    "        'hand1_str': combo[0],\n",
    "        'hand2_str': combo[1],\n",
    "        'hand1': hand1,\n",
    "        'hand2': hand2,\n",
    "        'equity_hand1': equity_hand1,\n",
    "        'equity_hand2': equity_hand2,\n",
    "        # 'res': res_local  # you can omit if you don't need per-trial data\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This list presumably contains all your 2-card \"types\" like 'AKs', 'AKo', 'QQ', etc.\n",
    "hand_types = range_construction.hands  # e.g. 169 items\n",
    "all_combos = list(itertools.combinations(hand_types, 2))\n",
    "\n",
    "# Number of parallel workers\n",
    "n_jobs = -1  # use all available CPU cores (you can set to something else, e.g., 4)\n",
    "\n",
    "# We'll do 500 or 1000 iterations per matchup for demonstration\n",
    "trials_per_matchup = 10000\n",
    "\n",
    "results = Parallel(n_jobs=n_jobs, backend=\"loky\")(\n",
    "    delayed(simulate_matchup)(combo, trials=trials_per_matchup) \n",
    "    for combo in all_combos\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved preflop_equity.csv and preflop_matchups.csv\n"
     ]
    }
   ],
   "source": [
    "equity_results = {}\n",
    "matchup_rows = []  # We'll collect the final matchup results here\n",
    "\n",
    "for r in results:\n",
    "    h1_str = r['hand1_str']\n",
    "    h2_str = r['hand2_str']\n",
    "    \n",
    "    eq_h1 = r['equity_hand1']\n",
    "    eq_h2 = r['equity_hand2']\n",
    "    \n",
    "    # Store for future averaging (equity by hand)\n",
    "    equity_results.setdefault(h1_str, []).append(eq_h1)\n",
    "    equity_results.setdefault(h2_str, []).append(eq_h2)\n",
    "    \n",
    "    # Also store a single row for the matchup\n",
    "    # (If you don't need trial-level data, no need for r['res'])\n",
    "    matchup_rows.append({\n",
    "        'hand1_str': h1_str,\n",
    "        'hand2_str': h2_str,\n",
    "        'equity_hand1': eq_h1,\n",
    "        'equity_hand2': eq_h2\n",
    "    })\n",
    "\n",
    "# 1) Compute average equity for each hand\n",
    "for hand_str, eq_list in equity_results.items():\n",
    "    equity_results[hand_str] = np.mean(eq_list)\n",
    "\n",
    "df_equity = pd.DataFrame(equity_results.items(), columns=['hand', 'equity'])\n",
    "df_equity.to_csv('../results/preflop_equity.csv', index=False)\n",
    "\n",
    "# 2) Save the single-row-per-matchup results\n",
    "df_matchups = pd.DataFrame(matchup_rows)\n",
    "df_matchups.to_csv('../results/preflop_matchups.csv', index=False)\n",
    "\n",
    "print(\"Saved preflop_equity.csv and preflop_matchups.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_equity.sort_values(by='equity', ascending=False, inplace=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
